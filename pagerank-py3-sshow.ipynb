{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Preliminary start-up code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Initialize SparkContext\n",
    "sc = SparkContext('local', 'PageRank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the links from polblogs_edges.jsonl\n",
    "# Each line is a JSON object like {\"1\": [3]}\n",
    "# Create LinksRDD as an RDD of (vertex_id, list of target vertex_ids)\n",
    "LinksRDD = sc.textFile('polblogs_edges.jsonl') \\\n",
    "    .map(lambda x: json.loads(x)) \\\n",
    "    .flatMap(lambda x: x.items()) \\\n",
    "    .map(lambda x: (int(x[0]), list(map(int, x[1]))))\n",
    "\n",
    "# Partition LinksRDD for better performance and persist it\n",
    "numPartitions = 12  # Adjust based on available cores\n",
    "LinksRDD = LinksRDD.partitionBy(numPartitions).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the names from polblogs_nodes.jsonl\n",
    "# Each line is a JSON object like {\"100monkeystyping.com\": 1}\n",
    "# Create namesRDD as an RDD of (vertex_id, URL)\n",
    "namesRDD = sc.textFile('polblogs_nodes.jsonl') \\\n",
    "    .map(lambda x: json.loads(x)) \\\n",
    "    .flatMap(lambda x: x.items()) \\\n",
    "    .map(lambda x: (int(x[1]), x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Get the total number of nodes\n",
    "N = namesRDD.count()\n",
    "\n",
    "# Initialize RankRDD with initial rank 1/N for each node\n",
    "RankRDD = namesRDD.map(lambda x: (x[0], 1.0 / N))\n",
    "\n",
    "# Partition RankRDD\n",
    "RankRDD = RankRDD.partitionBy(numPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- Define getContributions Function ------------------------\n",
    "def getContributions(linksAndRank):\n",
    "    j = linksAndRank[0]  # Current node ID\n",
    "    targets = linksAndRank[1][0]  # List of target node IDs\n",
    "    rankj = linksAndRank[1][1]  # Rank of node j\n",
    "    odegj = float(len(targets))  # Out-degree of node j\n",
    "    # For each target node i, emit (i, rankj / odegj)\n",
    "    return [ (i, rankj / odegj) for i in targets ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 pages after 10 iterations:\n",
      "Node ID: 798, URL: andrewsullivan.com, Rank: 0.051298048032891765\n",
      "Node ID: 990, URL: freerepublic.com, Rank: 0.03403194299683014\n",
      "Node ID: 1086, URL: kausfiles.com, Rank: 0.03121307385535634\n",
      "Node ID: 1067, URL: jewishworldreview.com, Rank: 0.030829633782859366\n",
      "Node ID: 514, URL: politicalwire.com, Rank: 0.03048333432899019\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 pages after 20 iterations:\n",
      "Node ID: 798, URL: andrewsullivan.com, Rank: 0.07280718174008817\n",
      "Node ID: 990, URL: freerepublic.com, Rank: 0.04886749550791796\n",
      "Node ID: 1086, URL: kausfiles.com, Rank: 0.044045937358357344\n",
      "Node ID: 514, URL: politicalwire.com, Rank: 0.04373376487381114\n",
      "Node ID: 1067, URL: jewishworldreview.com, Rank: 0.04203850143962231\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 pages after 30 iterations:\n",
      "Node ID: 798, URL: andrewsullivan.com, Rank: 0.08204721632733827\n",
      "Node ID: 990, URL: freerepublic.com, Rank: 0.05516691702547013\n",
      "Node ID: 1086, URL: kausfiles.com, Rank: 0.04954698693272156\n",
      "Node ID: 514, URL: politicalwire.com, Rank: 0.04950982323038244\n",
      "Node ID: 1067, URL: jewishworldreview.com, Rank: 0.04681784687420618\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 351:==================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 pages after 40 iterations:\n",
      "Node ID: 798, URL: andrewsullivan.com, Rank: 0.08602349832670199\n",
      "Node ID: 990, URL: freerepublic.com, Rank: 0.05786922837051995\n",
      "Node ID: 514, URL: politicalwire.com, Rank: 0.05200416472793629\n",
      "Node ID: 1086, URL: kausfiles.com, Rank: 0.05191345030735264\n",
      "Node ID: 1067, URL: jewishworldreview.com, Rank: 0.04887176255571141\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# --------------------- PageRank Iterations ------------------------\n",
    "\n",
    "# Define the list of iteration counts\n",
    "iterations_list = [10, 20, 30, 40]\n",
    "\n",
    "for max_iter in iterations_list:\n",
    "    # Re-initialize RankRDD for each run\n",
    "    RankRDD = namesRDD.map(lambda x: (x[0], 1.0 / N))\n",
    "    RankRDD = RankRDD.partitionBy(numPartitions)\n",
    "\n",
    "    iter = 1\n",
    "    while iter <= max_iter:\n",
    "        # Join LinksRDD with RankRDD to get (node_id, (list of targets, rank))\n",
    "        LinksRankInfo = LinksRDD.join(RankRDD)\n",
    "\n",
    "        # Compute contributions from each node to its targets\n",
    "        flatContributions = LinksRankInfo.flatMap(getContributions)\n",
    "\n",
    "        # Sum contributions by target node ID to get new ranks\n",
    "        RankRDD = flatContributions.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "    # After max_iter iterations, get the top 5 pages\n",
    "    # Join RankRDD with namesRDD to get URLs\n",
    "    RankWithNames = RankRDD.join(namesRDD)\n",
    "\n",
    "    # Sort by rank descending and take top 5 nodes\n",
    "    top5 = RankWithNames.sortBy(lambda x: x[1][0], ascending=False).take(5)\n",
    "\n",
    "    # Display the results\n",
    "    print(f\"Top 5 pages after {max_iter} iterations:\")\n",
    "    for node_id, (rank, url) in top5:\n",
    "        print(f\"Node ID: {node_id}, URL: {url}, Rank: {rank}\")\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
