{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Preliminary start-up code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Initialize SparkContext\n",
    "sc = SparkContext('local', 'PageRank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the links from polblogs_edges.jsonl\n",
    "# Each line is a JSON object like {\"1\": [3]}\n",
    "# Create LinksRDD as an RDD of (vertex_id, list of target vertex_ids)\n",
    "LinksRDD = sc.textFile('polblogs_edges.jsonl') \\\n",
    "    .map(lambda x: json.loads(x)) \\\n",
    "    .flatMap(lambda x: x.items()) \\\n",
    "    .map(lambda x: (int(x[0]), list(map(int, x[1]))))\n",
    "\n",
    "# Partition LinksRDD for better performance and persist it\n",
    "numPartitions = 12  # Adjust based on available cores\n",
    "LinksRDD = LinksRDD.partitionBy(numPartitions).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the names from polblogs_nodes.jsonl\n",
    "# Each line is a JSON object like {\"100monkeystyping.com\": 1}\n",
    "# Create namesRDD as an RDD of (vertex_id, URL)\n",
    "namesRDD = sc.textFile('polblogs_nodes.jsonl') \\\n",
    "    .map(lambda x: json.loads(x)) \\\n",
    "    .flatMap(lambda x: x.items()) \\\n",
    "    .map(lambda x: (int(x[1]), x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Get the total number of nodes\n",
    "N = namesRDD.count()\n",
    "\n",
    "# Initialize RankRDD with initial rank 1/N for each node\n",
    "RankRDD = namesRDD.map(lambda x: (x[0], 1.0 / N))\n",
    "\n",
    "# Partition RankRDD\n",
    "RankRDD = RankRDD.partitionBy(numPartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- Define getContributions Function ------------------------\n",
    "def getContributions(linksAndRank):\n",
    "    j = linksAndRank[0]  # Current node ID\n",
    "    targets = linksAndRank[1][0]  # List of target node IDs\n",
    "    rankj = linksAndRank[1][1]  # Rank of node j\n",
    "    odegj = float(len(targets))  # Out-degree of node j\n",
    "    # For each target node i, emit (i, rankj / odegj)\n",
    "    return [ (i, rankj / odegj) for i in targets ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 pages after 10 iterations:\n",
      "Node ID: 798, URL: andrewsullivan.com, Rank: 0.051298048032891765\n",
      "Node ID: 990, URL: freerepublic.com, Rank: 0.03403194299683014\n",
      "Node ID: 1086, URL: kausfiles.com, Rank: 0.03121307385535634\n",
      "Node ID: 1067, URL: jewishworldreview.com, Rank: 0.030829633782859366\n",
      "Node ID: 514, URL: politicalwire.com, Rank: 0.03048333432899019\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 pages after 20 iterations:\n",
      "Node ID: 798, URL: andrewsullivan.com, Rank: 0.07280718174008817\n",
      "Node ID: 990, URL: freerepublic.com, Rank: 0.04886749550791796\n",
      "Node ID: 1086, URL: kausfiles.com, Rank: 0.044045937358357344\n",
      "Node ID: 514, URL: politicalwire.com, Rank: 0.04373376487381114\n",
      "Node ID: 1067, URL: jewishworldreview.com, Rank: 0.04203850143962231\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 pages after 30 iterations:\n",
      "Node ID: 798, URL: andrewsullivan.com, Rank: 0.08204721632733827\n",
      "Node ID: 990, URL: freerepublic.com, Rank: 0.05516691702547013\n",
      "Node ID: 1086, URL: kausfiles.com, Rank: 0.04954698693272156\n",
      "Node ID: 514, URL: politicalwire.com, Rank: 0.04950982323038244\n",
      "Node ID: 1067, URL: jewishworldreview.com, Rank: 0.04681784687420618\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 351:==================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 pages after 40 iterations:\n",
      "Node ID: 798, URL: andrewsullivan.com, Rank: 0.08602349832670199\n",
      "Node ID: 990, URL: freerepublic.com, Rank: 0.05786922837051995\n",
      "Node ID: 514, URL: politicalwire.com, Rank: 0.05200416472793629\n",
      "Node ID: 1086, URL: kausfiles.com, Rank: 0.05191345030735264\n",
      "Node ID: 1067, URL: jewishworldreview.com, Rank: 0.04887176255571141\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# --------------------- PageRank Iterations ------------------------\n",
    "\n",
    "# Define the list of iteration counts\n",
    "iterations_list = [10, 20, 30, 40]\n",
    "\n",
    "for max_iter in iterations_list:\n",
    "    # Re-initialize RankRDD for each run\n",
    "    RankRDD = namesRDD.map(lambda x: (x[0], 1.0 / N))\n",
    "    RankRDD = RankRDD.partitionBy(numPartitions)\n",
    "\n",
    "    iter = 1\n",
    "    while iter <= max_iter:\n",
    "        # Join LinksRDD with RankRDD to get (node_id, (list of targets, rank))\n",
    "        LinksRankInfo = LinksRDD.join(RankRDD)\n",
    "\n",
    "        # Compute contributions from each node to its targets\n",
    "        flatContributions = LinksRankInfo.flatMap(getContributions)\n",
    "\n",
    "        # Sum contributions by target node ID to get new ranks\n",
    "        RankRDD = flatContributions.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "    # After max_iter iterations, get the top 5 pages\n",
    "    # Join RankRDD with namesRDD to get URLs\n",
    "    RankWithNames = RankRDD.join(namesRDD)\n",
    "\n",
    "    # Sort by rank descending and take top 5 nodes\n",
    "    top5 = RankWithNames.sortBy(lambda x: x[1][0], ascending=False).take(5)\n",
    "\n",
    "    # Display the results\n",
    "    print(f\"Top 5 pages after {max_iter} iterations:\")\n",
    "    for node_id, (rank, url) in top5:\n",
    "        print(f\"Node ID: {node_id}, URL: {url}, Rank: {rank}\")\n",
    "    print(\"\\n\")\n"
   ]
  }
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the results\n",
    "\n",
    "10 iterations:\n",
    "    Top page: andrewsullivan.com with a score of 0.0513\n",
    "    Fifth page: politicalwire.com with a score of 0.0305\n",
    "    Range between the top page and the fifth page: 0.0513 - 0.0305 = 0.0208\n",
    "\n",
    "20 iterations:\n",
    "    Top page: andrewsullivan.com with a score of 0.0728\n",
    "    Fifth page: jewishworldreview.com with a score of 0.0420\n",
    "    Range between the top and fifth page: 0.0728 - 0.0420 = 0.0308\n",
    "\n",
    "30 iterations:\n",
    "    Top page: andrewsullivan.com with a score of 0.0820\n",
    "    Fifth page: jewishworldreview.com with a score of 0.0468\n",
    "    Range between the top and fifth page: 0.0820 - 0.0468 = 0.0352\n",
    "\n",
    "40 iterations:\n",
    "    Top page: andrewsullivan.com with a score of 0.0860\n",
    "    Fifth page: jewishworldreview.com with a score of 0.0489\n",
    "    Range between the top and fifth page: 0.0860 - 0.0489 = 0.0371\n",
    "\n",
    "\n",
    "As the number of iterations increases, the rank score gap between the highest-ranked and the fifth-ranked page grows. This indicates that higher iterations allow for more differentiation between the ranks.\n",
    "\n",
    "Stabilization of Rankings: The relative positions of the pages remain consistent after 30 iterations, but the scores still adjust slightly as iterations progress. It suggests the algorithm is converging but is still making small adjustments after 30 iterations.\n",
    "\n",
    "The PageRank algorithm clearly distinguishes the importance of pages over time, with the top page (andrewsullivan.com) steadily increasing its lead over the others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
